{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d3258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils import check_array, check_random_state\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "import gmm_agent\n",
    "from sklearn.datasets import make_classification\n",
    "from random import choices\n",
    "importlib.reload(gmm_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1371f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate classification problems of varying difficulty\n",
    "def problem_maker(n_samples=2000, n_classes=2, n_features=2, class_sep=1.0, flip_y=0.00, random_state=8):\n",
    "    X, Y = make_classification(n_samples=n_samples, \n",
    "                            n_features=n_features, \n",
    "                            n_informative=n_features, \n",
    "                            n_redundant=0, \n",
    "                            n_repeated=0, \n",
    "                            n_classes=n_classes, \n",
    "                            n_clusters_per_class=1, \n",
    "                            class_sep=class_sep, \n",
    "                            flip_y=flip_y, \n",
    "                            hypercube=True,\n",
    "                            random_state=random_state)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# critical number of samples for detecting a novel class with increasing class separation\n",
    "np.random.seed(1)\n",
    "critical_samples = []\n",
    "separations = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)\n",
    "fig.suptitle('Class separation')\n",
    "axis = [ax1, ax2, ax3, ax4]\n",
    "axis_index = 0\n",
    "for i in separations:\n",
    "    print(\"processing separation \" + str(i))\n",
    "    X, Y = problem_maker(class_sep=1, n_classes=2, random_state=1)\n",
    "    X_novel = np.random.normal(loc=[0.0, -1], scale=0.4, size=(500, 2))\n",
    "    cov = np.array([[0.0, -0.4], [1.7, 0.4]])\n",
    "    X_novel = np.dot(X_novel, cov)\n",
    "    X_novel = X_novel + np.array([1+i, 0])\n",
    "\n",
    "    # find the critical number of samples many times \n",
    "    # using different samples from the novel distribution and average the results\n",
    "    critical_sample_list = []\n",
    "    averaging_run = 0\n",
    "    failure_count = 0  # tracks number of times the new component was not discovered\n",
    "    num_averaging_runs = 10\n",
    "    total_runs = 0\n",
    "    while averaging_run < num_averaging_runs and total_runs < 100:\n",
    "        starting_num_components = 2\n",
    "        a = gmm_agent.Agent(train_data=X, num_components=starting_num_components, recluster_limit=1)\n",
    "\n",
    "        index = 1\n",
    "        while a.num_components == starting_num_components and index < len(X_novel):\n",
    "            a.classify(X_novel[np.random.choice(range(len(X_novel)))]) # randomly select each novel sample with replacement\n",
    "            index += 1\n",
    "        if index != len(X_novel): # only use the value if the model successfully updated\n",
    "            critical_sample_list.append(index)\n",
    "            averaging_run += 1\n",
    "            total_runs += 1\n",
    "        else:\n",
    "            failure_count += 1\n",
    "            total_runs += 1\n",
    "    \n",
    "    if total_runs < 100:\n",
    "        critical_sample_value = np.mean(critical_sample_list)\n",
    "\n",
    "        print(\"For class_sep=\" + str(i) + \", critical sample for detection: \" + str(critical_sample_value))\n",
    "        print(\"Failure rate: \" + str(failure_count / total_runs))\n",
    "        critical_samples.append(critical_sample_value)\n",
    "        print(\"class_sep: \" + str(i))\n",
    "#         plt.plot(X[:,0], X[:,1], ls='none', marker='.', color='blue')\n",
    "#         plt.plot(X_novel[:,0], X_novel[:,1], ls='none', marker='.', color='green')\n",
    "#         plt.show()\n",
    "        if axis_index < 4:\n",
    "            axis[axis_index].plot(X[:,0], X[:,1], ls='none', marker='.', color='blue')\n",
    "            axis[axis_index].plot(X_novel[:,0], X_novel[:,1], ls='none', marker='.', color='green')\n",
    "            axis_index += 1\n",
    "    else:\n",
    "        print()\n",
    "        print(\"*** 100 runs complete without reaching \" + str(num_averaging_runs) + \" successes  ***\")\n",
    "        print()\n",
    "#     plt.clf()\n",
    "# plt.plot(separations, critical_samples, ls='none', marker='o')\n",
    "# plt.title(\"Class separation vs. critical number of samples\")\n",
    "# plt.xlabel(\"Class Separation\")\n",
    "# plt.ylabel(\"Critical number of samples\")\n",
    "# plt.savefig(\"img_critcal_sample_vs_class_separation\", format='pdf')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0e13fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# critical number of samples for detecting a novel class with increasing variance\n",
    "np.random.seed(1)\n",
    "critical_samples = []\n",
    "separations = [2, 3, 4, 5, 6, 7, 8]\n",
    "for i in separations:\n",
    "    print()\n",
    "    X, Y = problem_maker(class_sep=1, n_classes=2, random_state=1)\n",
    "    X_novel = np.random.normal(loc=[0.0, -1], scale=0.1*i, size=(500, 2))\n",
    "#     print(np.mean(X_novel, axis=0))\n",
    "    cov = np.array([[0.0, -0.4], [1.7, 0.4]])\n",
    "    X_novel = np.dot(X_novel, cov)\n",
    "    X_novel = X_novel + np.array([2,0])\n",
    "    \n",
    "\n",
    "    # find the critical number of samples many times \n",
    "    # using different samples from the novel distribution and average the results\n",
    "    critical_sample_list = []\n",
    "    averaging_run = 0\n",
    "    failure_count = 0  # tracks number of times the new component was not discovered\n",
    "    num_averaging_runs = 25\n",
    "    total_runs = 0\n",
    "    while averaging_run < num_averaging_runs and total_runs < 100:\n",
    "        starting_num_components = 2\n",
    "        a = gmm_agent.Agent(train_data=X, num_components=starting_num_components, recluster_limit=1)\n",
    "\n",
    "        index = 1\n",
    "        while a.num_components == starting_num_components and index < len(X_novel):\n",
    "            a.classify(X_novel[np.random.choice(range(len(X_novel)))]) # randomly select each novel sample with replacement\n",
    "            index += 1\n",
    "        if index != len(X_novel): # only use the value if the model successfully updated\n",
    "            critical_sample_list.append(index)\n",
    "            averaging_run += 1\n",
    "            total_runs += 1\n",
    "        else:\n",
    "            failure_count += 1\n",
    "            total_runs += 1\n",
    "    \n",
    "    if total_runs < 100:\n",
    "        critical_sample_value = np.mean(critical_sample_list)\n",
    "\n",
    "        print(\"For scale=\" + str(0.1*i) + \", critical sample for detection: \" + str(critical_sample_value))\n",
    "        print(\"Failure rate: \" + str(failure_count / total_runs))\n",
    "        critical_samples.append(critical_sample_value)\n",
    "        plt.plot(X[:,0], X[:,1], ls='none', marker='.', color='blue')\n",
    "        plt.plot(X_novel[:,0], X_novel[:,1], ls='none', marker='.', color='green')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print()\n",
    "        print(\"*** 100 runs complete without reaching \" + str(num_averaging_runs) + \" successes  ***\")\n",
    "        print()\n",
    "        critical_samples.append(-1) # so the plot will still work, but will be obviously weird\n",
    "plt.plot([0.1*i for i in separations], critical_samples, ls='none', marker='o')\n",
    "plt.title(\"Critical number of samples vs. variance\")\n",
    "plt.xlabel(\"variance\")\n",
    "plt.ylabel(\"critical number of samples\")\n",
    "# plt.savefig(\"critical_number_vs_scale.pdf\", format='pdf')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71559940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detecting novel distributions in \"open space\" with different variance\n",
    "np.random.seed(1)\n",
    "critical_samples = []\n",
    "scales = [0.1, 0.5, 1, 2, 3, 4, 5]\n",
    "for i in scales:\n",
    "    X, Y = problem_maker(class_sep=1, n_classes=2, random_state=1)\n",
    "    X_novel = np.random.normal(loc=[0.0, -1], scale=i, size=(500, 2))\n",
    "    cov = np.array([[0.0, -0.4], [1.7, 0.4]])\n",
    "    X_novel = np.dot(X_novel, cov)\n",
    "    X_novel = X_novel + np.array([12, 0])\n",
    "\n",
    "    # find the critical number of samples many times \n",
    "    # using different samples from the novel distribution and average the results\n",
    "    critical_sample_list = []\n",
    "    averaging_run = 0\n",
    "    failure_count = 0  # tracks number of times the new component was not discovered\n",
    "    num_averaging_runs = 25\n",
    "    total_runs = 0\n",
    "    while averaging_run < num_averaging_runs and total_runs < 100:\n",
    "        starting_num_components = 2\n",
    "        a = gmm_agent.Agent(train_data=X, num_components=starting_num_components, recluster_limit=1)\n",
    "\n",
    "        index = 1\n",
    "        while a.num_components == starting_num_components and index < len(X_novel):\n",
    "            a.classify(X_novel[np.random.choice(range(len(X_novel)))]) # randomly select each novel sample with replacement\n",
    "            index += 1\n",
    "        if index != len(X_novel): # only use the value if the model successfully updated\n",
    "            critical_sample_list.append(index)\n",
    "            averaging_run += 1\n",
    "            total_runs += 1\n",
    "        else:\n",
    "            failure_count += 1\n",
    "            total_runs += 1\n",
    "    \n",
    "    if total_runs < 100:\n",
    "        critical_sample_value = np.mean(critical_sample_list)\n",
    "\n",
    "        print(\"For scale=\" + str(i) + \", critical sample for detection: \" + str(critical_sample_value))\n",
    "        print(\"Failure rate: \" + str(failure_count / total_runs))\n",
    "        critical_samples.append(critical_sample_value)\n",
    "        plt.plot(X[:,0], X[:,1], ls='none', marker='.', color='blue')\n",
    "        plt.plot(X_novel[:,0], X_novel[:,1], ls='none', marker='.', color='green')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print()\n",
    "        print(\"*** 100 runs complete without reaching \" + str(num_averaging_runs) + \" successes  ***\")\n",
    "        print()\n",
    "        critical_samples.append(-1) # so the plot will still work, but will be obviously weird\n",
    "plt.plot([i for i in scales], critical_samples, ls='none', marker='o')\n",
    "plt.title(\"Critical number of samples vs. variance - open space\")\n",
    "plt.xlabel(\"scale\")\n",
    "plt.ylabel(\"critical number of samples\")\n",
    "# plt.savefig(\"critical_number_variance_open.pdf\", format='pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
